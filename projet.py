# -*- coding: utf-8 -*-
"""titanic-survival-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ua-q7sy2c6W-NK42C0BfYNIL3RAbvT9B
"""

from IPython.core.display import display, HTML

#Icone kaggle
display(HTML("""
<a href="https://www.kaggle.com/competitions/titanic/overview" target="_blank">
    <img align="left" alt="Kaggle" title="Open in Kaggle"
         src="https://kaggle.com/static/images/open-in-kaggle.svg" style="width:200px;">
</a>
"""))

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Introduction
</h1>
<p style="font-family: Georgia; font-size: 14pt; font-weight: bold; color:#4cd1ff;">
Ce projet explore le c√©l√®bre d√©fi Titanic de Kaggle, avec pour objectif de pr√©dire la survie des passagers en fonction de leurs caract√©ristiques.
<br><br>
√Ä l'aide de mod√®les tels que la R√©gression Logistique, RandomForest et XGBoost,
combin√©s √† des techniques comme les valeurs SHAP et l‚Äôimportance par permutation,
nous visons √† concilier pr√©cision et compr√©hension des pr√©dictions.
<br><br>
Nous travaillerons en √©quipe de 4 membres pour garantir une collaboration efficace et atteindre les objectifs fix√©s. L'outil collaboratif GitHub sera utilis√© pour g√©rer le code source,
avec une strat√©gie de branches et des pull requests pour assurer la qualit√© et la revue du code. Un pipeline CI/CD sera mis en place pour automatiser les tests, le linting, et, potentiellement,
la containerisation du projet.</p>
üö¢‚ú®
"""))

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
from sklearn.model_selection import GridSearchCV
import joblib
from sklearn.ensemble import StackingClassifier
from sklearn.inspection import permutation_importance
import shap

# D√©finir les styles visuels
plt.style.use('ggplot')
sns.set_context('notebook')
shap.initjs()

HO_TUNING = True #on n‚Äôactive pas la recherche d‚Äôhyperparam√®tres de Grid Search et Random Search
LOAD_MODEL = True #on charge le mod√®le d√©j√† sauvegard√© depuis le dossier models_path, plut√¥t que d‚Äôen entra√Æner un nouveau.

# Chemin du dossier models dans le r√©pertoire local
models_path = r"C:\Users\mbena\OneDrive\Bureau\python TP\BUT3FA\Titanic-Survival-Prediction-main\Titanic-Survival-Predict-main\models"

# On v√©rifie si le dossier models existe, sinon le cr√©e
if not os.path.exists(models_path):
    os.mkdir(models_path)

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 1: Data Loading et Exploration des Donn√©es
</h1>
"""))

# Configuration des styles pour les graphiques
plt.style.use('ggplot')
sns.set_context('notebook')

# Parcours des fichiers dans un r√©pertoire sp√©cifi√©
base_path = r"C:\Users\mbena\OneDrive\Bureau\python TP\BUT3FA\Titanic-Survival-Prediction-main\Titanic-Survival-Predict-main"
for dirname, _, filenames in os.walk(base_path):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Code minimal pour garantir le fonctionnement
print("\n--- T√¢che 0 : Exploration du r√©pertoire termin√©e ---")

import os

def get_models_path():
    """
    Retourne le chemin pour enregistrer ou charger les mod√®les.
    - Si l'environnement est Kaggle, retourne le chemin Kaggle.
    - Sinon, retourne un chemin local bas√© sur le r√©pertoire du projet.
    Cr√©e le r√©pertoire si n√©cessaire.
    """
    if os.path.exists("/kaggle/working/"):
        # Chemin pour l'environnement Kaggle
        models_path = "/kaggle/working/models/"
    else:
        # Chemin pour l'environnement local (r√©pertoire du projet)
        project_path = r"C:\Users\mbena\OneDrive\Bureau\python TP\BUT3FA\Titanic-Survival-Prediction-main\Titanic-Survival-Predict-main"
        models_path = os.path.join(project_path, "models")

    # Cr√©ation du r√©pertoire s'il n'existe pas
    os.makedirs(models_path, exist_ok=True)
    return models_path

# Exemple d'utilisation
if __name__ == "__main__":
    models_path = get_models_path()
    print(f"Le chemin du dossier 'models' est : {models_path}")

from google.colab import drive
drive.mount('/content/drive')

# √âtape 2 : Chargement du jeu de donn√©es
# Charger les fichiers CSV contenant les donn√©es d'entra√Ænement et de test
train_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv')
test_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv')

# On affiche les informations de base sur le jeu de donn√©es d'entra√Ænement
print("Training Set Information:")
train_df.info()

# On affiche les informations de base sur le jeu de donn√©es de test
print("\nTest Set Information:")
test_df.info()

# √âtape 3 : Statistiques de base et exploration initiale des donn√©es
# Affichage des 5 premi√®res lignes du jeu de donn√©es d'entra√Ænement pour aper√ßu
print("\nLes 5 premi√®res lignes du jeu d'entra√Ænement :")
print(train_df.head())

# On v√©rifie les valeurs manquantes dans le jeu de donn√©es d'entra√Ænement et de test
print("\nValeurs manquantes dans le jeu d'entra√Ænement :")
print(train_df.isnull().sum())

print("\nValeurs manquantes dans le jeu de test :")
print(test_df.isnull().sum())

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 2: Analyse Exploratoire des Donn√©es (EDA)
</h1>
"""))

# Import des biblioth√®ques n√©cessaires
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# √âtape 4 : Analyse exploratoire des donn√©es (EDA)

# Visualisation de la r√©partition de la variable 'Survived' dans l'ensemble d'entra√Ænement
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Survived', palette='Set2')
plt.title('R√©partition de la variable Survived')
plt.show()

# Visualisation de la distribution des classes de passagers (Pclass)
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Pclass', palette='Set3')
plt.title('R√©partition des classes de passagers (Pclass)')
plt.show()

# Distribution de l'√¢ge par rapport √† la survie
plt.figure(figsize=(10, 6))
sns.histplot(train_df[train_df['Survived'] == 1]['Age'].dropna(), bins=20, color='green', label='Surv√©cu', kde=True)
sns.histplot(train_df[train_df['Survived'] == 0]['Age'].dropna(), bins=20, color='red', label='Non surv√©cu', kde=True)
plt.title('Distribution des √¢ges par rapport √† la survie')
plt.legend()
plt.show()

# Matrice de corr√©lation pour v√©rifier les relations entre les variables num√©riques
# On filtre uniquement les colonnes num√©riques
numeric_features = train_df.select_dtypes(include=[np.number])

plt.figure(figsize=(12, 8))
sns.heatmap(numeric_features.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matrice de corr√©lation')
plt.show()

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 3: Data Preprocessing
</h1>
"""))

train_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv')
test_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv')

# √âtape 1 : Gestion des valeurs manquantes

# On Remplit les valeurs manquantes d'Age avec la m√©diane par groupe de Pclass
train_df['Age'] = train_df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))
test_df['Age'] = test_df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))

# Ajout d'une colonne AgeGroup pour cat√©goriser l'√¢ge en groupes
for df in [train_df, test_df]:
    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 80], labels=[0, 1, 2, 3, 4])

# Remplis des valeurs manquantes d'Embarked avec la valeur la plus fr√©quente
train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)

# Remplis les valeurs manquantes de Fare dans test_df avec la m√©diane par groupe de Pclass
test_df['Fare'] = test_df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))

# Ajout d'une colonne FareBin pour diviser Fare en 4 intervalles √©gaux
for df in [train_df, test_df]:
    df['FareBin'] = pd.qcut(df['Fare'], 4, labels=[0, 1, 2, 3])

# √âtape 2 : Cr√©ation de nouvelles caract√©ristiques

# Ajout d'une colonne Age*Pclass comme interaction entre AgeGroup et Pclass
for df in [train_df, test_df]:
    df['Age*Pclass'] = df['AgeGroup'].astype(int) * df['Pclass']

# Ajout d'une colonne FamilySize combinant SibSp et Parch
train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1
test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1

# Ajout de la  colonne IsAlone : 1 si le passager est seul, sinon 0
train_df['IsAlone'] = 1
train_df['IsAlone'].loc[train_df['FamilySize'] > 1] = 0
test_df['IsAlone'] = 1
test_df['IsAlone'].loc[test_df['FamilySize'] > 1] = 0

# Extraire Title √† partir de la colonne Name
train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
test_df['Title'] = test_df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# Remplacer les titres rares par Rare
rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']
train_df['Title'] = train_df['Title'].replace(rare_titles, 'Rare')
test_df['Title'] = test_df['Title'].replace(rare_titles, 'Rare')

# Standardiser les titres courants (ex. Mlle devient Miss, Mme devient Mrs)
train_df['Title'] = train_df['Title'].replace(['Mlle', 'Ms'], 'Miss')
train_df['Title'] = train_df['Title'].replace('Mme', 'Mrs')
test_df['Title'] = test_df['Title'].replace(['Mlle', 'Ms'], 'Miss')
test_df['Title'] = test_df['Title'].replace('Mme', 'Mrs')

# √âtape 3 : Encodage des variables cat√©goriques

# Calculer FamilySurvival comme le taux de survie moyen par taille de famille
family_survival_rate = train_df.groupby('FamilySize')['Survived'].mean().to_dict()

# Appliquer FamilySurvival aux deux DataFrames
for df in [train_df, test_df]:
    df['FamilySurvival'] = df['FamilySize'].map(family_survival_rate)
    df['FamilySurvival'] = df['FamilySurvival'].fillna(0)

# Mapper Sex en valeurs num√©riques : 0 pour homme, 1 pour femme
train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})

# Mapper Embarked en valeurs num√©riques : S=0, C=1, Q=2
train_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
test_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

# Mapper Title en valeurs num√©riques
title_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Rare': 4}
train_df['Title'] = train_df['Title'].map(title_mapping)
test_df['Title'] = test_df['Title'].map(title_mapping)

# Extraire Deck √† partir de Cabin et remplacer les valeurs manquantes par 'M'
for df in [train_df, test_df]:
    df['Deck'] = df['Cabin'].str[0]
    df['Deck'] = df['Deck'].fillna('M')

# Mapper Deck en cat√©gories num√©riques
deck_mapping = {deck: idx for idx, deck in enumerate(sorted(train_df['Deck'].unique()))}
train_df['Deck'] = train_df['Deck'].map(deck_mapping)
test_df['Deck'] = test_df['Deck'].map(deck_mapping)

# Supprimer les colonnes inutiles pour la mod√©lisation
train_df = train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])
test_df = test_df.drop(columns=['Name', 'Ticket', 'Cabin'])

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 4: Model Building
</h1>
"""))

# Etape 1 : S√©paration des donn√©es d'entra√Ænement en caract√©ristiques (X) et cible (y)
X = train_df.drop(columns=['Survived'])
y = train_df['Survived']

# Division des donn√©es d'entra√Ænement en ensembles d'entra√Ænement et de validation pour √©valuer le mod√®le
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Fonction pour √©valuer les mod√®les
def evaluate_model(model, X_train, y_train, X_val, y_val):
    model.fit(X_train, y_train)  # Entra√Ænement du mod√®le
    y_pred = model.predict(X_val)  # Pr√©diction sur l'ensemble de validation

    # Calcul et affichage de la pr√©cision
    accuracy = accuracy_score(y_val, y_pred)
    print(f"Pr√©cision : {accuracy:.4f}")

    # On affiche la matrice de confusion et du rapport de classification
    print("Matrice de confusion :")
    print(confusion_matrix(y_val, y_pred))
    print("\nRapport de classification :")
    print(classification_report(y_val, y_pred))

    return model

# Etape 2 : Regression Logistique
print("\n---  Regression Logistique ---")
logreg = LogisticRegression(max_iter=1000,
                            random_state=42)
logreg = evaluate_model(logreg, X_train, y_train,
                        X_val, y_val)

# Etape 3: RandomForest
print("\n--- Classificateur RandomForest  ---")
rf = RandomForestClassifier(n_estimators=100,
                            random_state=42)
rf = evaluate_model(rf, X_train, y_train,
                    X_val, y_val)

# Etape 4 : MultiLayer Perceptron (MLP)
print("\n--- Classificateur MLP ---")
mlp = MLPClassifier(alpha=0.06,
                    hidden_layer_sizes=(50, 50),
                    learning_rate_init=0.03,
                    max_iter=158)  # Initialisation du mod√®le MLP
mlp = evaluate_model(mlp, X_train,
                     y_train,
                     X_val, y_val)  # √âvaluation du mod√®le avec les donn√©es

# Etape 5 : Classifieur XGBoost
print("\n--- XGBoost Classifier ---")
xgb_model = xgb.XGBClassifier(use_label_encoder=False,
                              enable_categorical=True,
                              eval_metric='logloss',
                              random_state=42)
xgb_model = evaluate_model(xgb_model,
                           X_train,
                           y_train,
                           X_val, y_val)

# Apr√®s avoir entra√Æn√© logreg, rf, xgb_model
if not HO_TUNING:

    import joblib
    import os

    # On v√©rifie que le dossier /content/drive/MyDrive/Titanic-Survival-Predict-main/models existe dans le drive
    save_dir = "/content/drive/MyDrive/Titanic-Survival-Predict-main/models"
    os.makedirs(save_dir, exist_ok=True)

    # Chemins de sauvegarde
    logreg_path = os.path.join(save_dir, "logistic_regression_model.pkl")
    rf_path = os.path.join(save_dir, "random_forest_model.pkl")
    xgb_path = os.path.join(save_dir, "xgboost_model.pkl")

    # On sauvegarde
    joblib.dump(logreg, logreg_path)
    print(f"Mod√®le logreg sauvegard√© : {logreg_path}")

    joblib.dump(rf, rf_path)
    print(f"Mod√®le RandomForest sauvegard√© : {rf_path}")

    joblib.dump(xgb_model, xgb_path)
    print(f"Mod√®le XGBoost sauvegard√© : {xgb_path}")

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 5: Comparaison des mod√®les
</h1>
"""))

from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import numpy as np

# On cr√©e un dictionnaire de mod√®les comme avant
models = {
    'Logistic Regression': logreg,
    'RandomForest': rf,
    'XGBoost': xgb_model
}

# On d√©finit le K-fold
kf = KFold(n_splits=5,
           shuffle=True,
           random_state=42)

print("\n--- Scores de validation crois√©e (m√©thode manuelle) ---")

for name, model in models.items():
    scores = []
    for train_idx, val_idx in kf.split(X_train):
        X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]
        y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]

        # Entra√Ænement sur le fold d'entra√Ænement
        model.fit(X_t, y_t)
        # Pr√©diction sur le fold de validation
        y_pred = model.predict(X_v)

        # Calcul de l'accuracy
        scores.append(accuracy_score(y_v, y_pred))

    print(f"{name}: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})")

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 6 : Optimisation des hyperparam√®tres
</h1>
"""))

if HO_TUNING:
    # Etape 1 : Optimisation des hyperparam√®tres pour la r√©gression logistique
    print("\n--- Optimisation des hyperparam√®tres : R√©gression Logistique ---")
    logreg_params = {
        'C': [0.01, 0.1, 1, 10, 100],  # Force de r√©gularisation
        'solver': ['liblinear', 'lbfgs'],  # Types de solveurs
        'max_iter': [200, 500, 1000]  # Nombre maximum d'it√©rations
    }

    # Recherche des meilleurs hyperparam√®tres avec validation crois√©e
    logreg_grid = GridSearchCV(LogisticRegression(random_state=42), logreg_params, cv=5, scoring='accuracy')
    logreg_grid.fit(X_train, y_train)

    # Affichage des meilleurs hyperparam√®tres et r√©cup√©ration du meilleur mod√®le
    print(f"Meilleurs hyperparam√®tres pour la r√©gression logistique : {logreg_grid.best_params_}")
    best_logreg = logreg_grid.best_estimator_

logreg_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/models"

import joblib
from google.colab import files

# Sauvegarde localement dans /content/
logreg_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/logistic_regression_model.pkl"
joblib.dump(best_logreg, logreg_model_path)
print(f"Le mod√®le de Regression Logistique est bien sauvegard√© localement  et manuellement dans le dossier models depuis le Drive {logreg_model_path}")
final_logreg = best_logreg
# T√©l√©chargement automatique
files.download(logreg_model_path)

"""
if HO_TUNING:
    # Etape 2 : Optimisation des hyperparam√®tres pour RandomForest
    print("\n--- Optimisation des hyperparam√®tres : RandomForest ---")
    rf_params = {
        'n_estimators': [100, 200, 500],  # Nombre d'arbres dans la for√™t
        'max_depth': [None, 10, 20, 30],  # Profondeur maximale des arbres
        'min_samples_split': [2, 10, 20],  # Nombre minimum d'√©chantillons requis pour diviser un n≈ìud
        'min_samples_leaf': [1, 5, 10],  # Nombre minimum d'√©chantillons requis dans une feuille
        'bootstrap': [True, False]  # Utilisation ou non d'√©chantillons bootstrap
    }

    # Recherche des meilleurs hyperparam√®tres avec validation crois√©e
    rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy')
    rf_grid.fit(X_train, y_train)

    # Affichage des meilleurs hyperparam√®tres et r√©cup√©ration du meilleur mod√®le
    print(f"Meilleurs hyperparam√®tres pour RandomForest : {rf_grid.best_params_}")
    best_rf = rf_grid.best_estimator_
"""

from sklearn.model_selection import RandomizedSearchCV

# Param√®tres optimis√©s avec moins de combinaisons
rf_params = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 10],
    'min_samples_leaf': [1, 5],
    'bootstrap': [True]
}

# Sous-√©chantillonnage des donn√©es
X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.2, random_state=42)

# RandomizedSearchCV pour une recherche plus rapide
rf_random = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=rf_params,
    n_iter=10,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,  # Utilisation de tous les c≈ìurs disponibles
    verbose=2,  # Afficher les √©tapes
    random_state=42
)

# Ajustement du mod√®le
rf_random.fit(X_train_sampled, y_train_sampled)

# Meilleurs param√®tres
print(f"Meilleurs hyperparam√®tres pour RandomForest : {rf_random.best_params_}")
best_rf = rf_random.best_estimator_

import joblib
from google.colab import files

# Sauvegarde localement dans /content/
local_path = "/content/random_forest_model.pkl"
joblib.dump(best_rf, local_path)
print(f"Le mod√®le RandomForest est bien sauvegard√© localement  et manuellement dans le dossier models depuis le Drive {local_path}")
final_rf=best_rf
# T√©l√©chargement automatique
files.download(local_path)

import xgboost
import sklearn
print(xgboost.__version__)
print(sklearn.__version__)

# -----------------------------------------
# PARTIE : Import & Donn√©es
# -----------------------------------------
import itertools
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, KFold

HO_TUNING = True  # active l'optimisation manuelle

# Suppose qu'on a d√©j√† X_train, y_train d√©finis, par ex.:
# X = ...
# y = ...
# X_train, X_val, y_train, y_val = train_test_split(X, y, ...)

# -----------------------------------------
# PARTIE : Entra√Ænement manuel XGBoost
# -----------------------------------------
if HO_TUNING:
    print("\n--- Ajustement des hyperparam√®tres : XGBoost (approche manuelle) ---")

    # Param√®tres comme dans GridSearchCV
    xgb_params = {
        'n_estimators': [100, 200, 500],
        'max_depth': [3, 6, 10],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 1.0],
        'colsample_bytree': [0.8, 1.0],
    }

    best_score = 0.0
    best_params = None

    # KFold identique √† cv=5
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    # G√©n√©ration de toutes les combinaisons
    import itertools
    param_keys = list(xgb_params.keys())
    param_values = list(xgb_params.values())

    for combo in itertools.product(*param_values):
        current_params = dict(zip(param_keys, combo))

        # On cr√©e un XGBClassifier
        model = xgb.XGBClassifier(
            enable_categorical=True,  # Ajout de ce param√®tre
            eval_metric='logloss',
            random_state=42,
            **current_params
        )

        # Validation crois√©e manuelle
        cv_scores = []
        for train_idx, val_idx in kf.split(X_train):
            X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]
            y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]

            model.fit(X_t, y_t)
            y_pred = model.predict(X_v)
            cv_scores.append(accuracy_score(y_v, y_pred))

        mean_score = np.mean(cv_scores)

        if mean_score > best_score:
            best_score = mean_score
            best_params = current_params

    print(f"Meilleurs hyperparam√®tres XGBoost : {best_params}")
    print(f"Score en validation crois√©e : {best_score:.4f}")

    # On entra√Æne le meilleur mod√®le final
    best_xgb = xgb.XGBClassifier(
        enable_categorical=True,  # Ajout de ce param√®tre
        eval_metric='logloss',
        random_state=42,
        **best_params
    )
    best_xgb.fit(X_train, y_train)

    # √âvalue sur l'ensemble X_val si besoin
    y_pred_val = best_xgb.predict(X_val)
    val_acc = accuracy_score(y_val, y_pred_val)
    print(f"Accuracy sur l'ensemble de validation : {val_acc:.4f}")

else:
    # Si HO_TUNING = False, on peut
    # soit laisser un XGB par d√©faut,
    # soit ne rien faire
    best_xgb = xgb.XGBClassifier().fit(X_train, y_train)

import joblib
from google.colab import files

# Sauvegarde localement dans /content/
local_path = "/content/xgboost_model.pkl"
joblib.dump(best_xgb, local_path)
print(f"Le mod√®le XGBoost est bien sauvegard√© localement  et manuellement dans le dossier models depuis le Drive {local_path}")
final_xgb=best_xgb
# T√©l√©chargement automatique
files.download(local_path)

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 7 : Chargement des mod√®les pr√©-entra√Æn√©s
</h1>
"""))

if LOAD_MODEL:
    # Charger le mod√®le de r√©gression logistique
    logreg_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/logistic_regression_model.pkl'
    final_logreg = joblib.load(logreg_model_path)
    print(f"Mod√®le de r√©gression logistique charg√© depuis {logreg_model_path}")

    # Charger le mod√®le RandomForest
    rf_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/random_forest_model.pkl'
    final_rf = joblib.load(rf_model_path)
    print(f"Mod√®le RandomForest charg√© depuis {rf_model_path}")

    # Charger le mod√®le XGBoost
    xgb_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/xgboost_model.pkl'
    final_xgb = joblib.load(xgb_model_path)
    print(f"Mod√®le XGBoost charg√© depuis {xgb_model_path}")

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 8: Model Stacking</h1>
"""))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pandas as pd

# √âtape 1 : G√©n√©rer des pr√©dictions des mod√®les de base sur l'ensemble d'entra√Ænement
print("\n--- G√©n√©ration des pr√©dictions des mod√®les de base sur l'ensemble d'entra√Ænement ---")
train_pred_logreg = final_logreg.predict(X_train)
train_pred_rf = final_rf.predict(X_train)
train_pred_xgb = final_xgb.predict(X_train)

# Cr√©er un DataFrame avec ces pr√©dictions
train_meta_features = pd.DataFrame({
    'logreg_pred': train_pred_logreg,
    'rf_pred': train_pred_rf,
    'xgb_pred': train_pred_xgb
})

print("Pr√©dictions des mod√®les de base g√©n√©r√©es avec succ√®s.")

# √âtape 2 : Entra√Æner le Mod√®le Meta sur ces Pr√©dictions
print("\n--- Entra√Ænement du mod√®le Meta (R√©gression Logistique) ---")
meta_model = LogisticRegression(max_iter=1000, random_state=42)
meta_model.fit(train_meta_features, y_train)
print("Mod√®le Meta entra√Æn√© avec succ√®s.")

# √âtape 3 : G√©n√©rer des pr√©dictions des mod√®les de base sur l'ensemble de validation
print("\n--- G√©n√©ration des pr√©dictions des mod√®les de base sur l'ensemble de validation ---")
val_pred_logreg = final_logreg.predict(X_val)
val_pred_rf = final_rf.predict(X_val)
val_pred_xgb = final_xgb.predict(X_val)

# Cr√©er un DataFrame avec ces pr√©dictions
val_meta_features = pd.DataFrame({
    'logreg_pred': val_pred_logreg,
    'rf_pred': val_pred_rf,
    'xgb_pred': val_pred_xgb
})

print("Pr√©dictions des mod√®les de base sur l'ensemble de validation g√©n√©r√©es avec succ√®s.")

# √âtape 4 : Utiliser le Mod√®le Meta pour Pr√©dire sur l'Ensemble de Validation
print("\n--- Pr√©diction avec le mod√®le Meta ---")
y_pred_stack = meta_model.predict(val_meta_features)

# √âtape 5 : √âvaluer les Performances
print("\n--- √âvaluation des Performances du Mod√®le Empil√© ---")
stack_accuracy = accuracy_score(y_val, y_pred_stack)
print(f"Accuracy du mod√®le empil√© : {stack_accuracy:.4f}")

print("Matrice de confusion du mod√®le empil√© :")
print(confusion_matrix(y_val, y_pred_stack))

print("\nRapport de classification du mod√®le empil√© :")
print(classification_report(y_val, y_pred_stack))

# Optionnel : Sauvegarder le Mod√®le Meta
stack_meta_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/stacking_meta_model.pkl"
joblib.dump(meta_model, stack_meta_model_path)
print(f"\nLe mod√®le empil√© (meta) est bien sauvegard√© dans {stack_meta_model_path}")

"""
# Optionnel : Sauvegarder le Mod√®le Meta
stack_meta_model_local_path = "/content/stacking_meta_model.pkl"
joblib.dump(meta_model, stack_meta_model_local_path)
print(f"\nLe mod√®le empil√© (meta) est bien sauvegard√© localement √† : {stack_meta_model_local_path}")

# T√©l√©charger le mod√®le meta pour l'ajouter manuellement √† ton Drive
files.download(stack_meta_model_local_path)
"""

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 9: IA Explicable (XAI)</h1>
"""))

# √âtape 1 : Extraire les coefficients et les noms des caract√©ristiques correspondants
coefficients = logreg.coef_[0]
feature_names = X.columns

# √âtape 2 : Associer les coefficients aux noms des caract√©ristiques et trier par valeur absolue
coef_feature_pairs = sorted(
    zip(coefficients, feature_names),
    key=lambda x: abs(x[0]),
    reverse=True
)

# √âtape 3 : Extraire les 10 meilleures caract√©ristiques et leurs coefficients
top_ten_features = coef_feature_pairs[:10]
sorted_coefficients, sorted_feature_names = zip(*top_ten_features)

# √âtape 4 : Visualiser les 10 coefficients les plus importants
plt.figure(figsize=(10, 6))
plt.barh(sorted_feature_names, sorted_coefficients, color='skyblue')
plt.xlabel('Valeur des coefficients')
plt.ylabel('Nom des caract√©ristiques')
plt.title('Top 10 des coefficients de la r√©gression logistique (tri√©s par valeur absolue)')
plt.gca().invert_yaxis()  # Inverser l'axe y pour afficher le coefficient le plus √©lev√© en haut
plt.tight_layout()  # Ajuster la disposition pour une meilleure visualisation
plt.show()

# √âtape 1 : Extraire les importances des caract√©ristiques et cr√©er un DataFrame
importances = rf.feature_importances_
feature_importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# √âtape 2 : S√©lectionner les N caract√©ristiques les plus importantes
top_n = 10
top_features = feature_importance_df.head(top_n)

# √âtape 3 : Visualiser les N caract√©ristiques les plus importantes
plt.figure(figsize=(12, 6))
plt.barh(top_features['Feature'], top_features['Importance'], color='lightgreen', align='center')
plt.xlabel('Importance des caract√©ristiques')
plt.ylabel('Nom des caract√©ristiques')
plt.title(f'Top {top_n} des caract√©ristiques les plus importantes (RandomForest)')
plt.gca().invert_yaxis()  # Afficher les caract√©ristiques les plus importantes en haut
plt.tight_layout()  # Ajuster la disposition pour une meilleure visualisation
plt.show()

# √âtape 1 : Calculer les importances par permutation
perm_importance = permutation_importance(mlp, X_val, y_val, n_repeats=10, random_state=42)

# √âtape 2 : Extraire et trier les importances des caract√©ristiques
feature_importances = perm_importance.importances_mean
sorted_idx = feature_importances.argsort()[::-1]  # Indices des caract√©ristiques tri√©s par importance (ordre d√©croissant)
top_n = 10  # Nombre de caract√©ristiques principales √† afficher

# √âtape 3 : S√©lectionner les N meilleures caract√©ristiques et leurs noms
top_features = [X.columns[i] for i in sorted_idx[:top_n]]
top_importances = feature_importances[sorted_idx[:top_n]]

# √âtape 4 : Visualiser les N meilleures importances des caract√©ristiques par permutation
plt.figure(figsize=(10, 6))
plt.barh(top_features, top_importances, color='cornflowerblue')
plt.xlabel("Importance des caract√©ristiques")
plt.ylabel("Nom des caract√©ristiques")
plt.title(f"Top {top_n} importances des caract√©ristiques par permutation")
plt.gca().invert_yaxis()  # Afficher la caract√©ristique avec la plus grande importance en haut
plt.tight_layout()  # Ajuster la mise en page pour √©viter les chevauchements
plt.show()

# √âtape 1 : Ici, on initialise l'explicateur SHAP pour le mod√®le RandomForest
explainer = shap.Explainer(rf)

# √âtape 2 : Calcule des valeurs SHAP
shap_values = explainer(X_train)

# √âtape 3 : Affichage des probabilit√©s de pr√©diction du mod√®le pour la premi√®re observation
first_observation_proba = rf.predict_proba([X_train.iloc[0]])[0]
print(f"Probabilit√©s de pr√©diction pour la premi√®re observation : {first_observation_proba}")

# √âtape 4 : G√©n√©rer un graphique en cascade (waterfall) SHAP pour la premi√®re observation
plt.title("Graphique en cascade SHAP pour la premi√®re observation")
shap.plots.waterfall(shap_values[0, :, 1])  # Valeurs SHAP pour la classe d'int√©r√™t (par exemple, classe 1 pour la survie)



display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 10: Cr√©ation du fichier de soumission
</h1>
"""))

# √âtape 1 : Pr√©paration du jeu de test pour les pr√©dictions
# S'assurer que le jeu de test a les m√™mes colonnes de caract√©ristiques que le jeu d'entra√Ænement (apr√®s pr√©traitement)
X_test = test_df.drop(columns=['PassengerId'])  # PassengerId sera utilis√© dans la soumission, donc on le supprime pour les pr√©dictions

from sklearn.linear_model import LogisticRegression

# √âtape 1 : G√©n√©rer les pr√©dictions des mod√®les de base sur l'ensemble d'entra√Ænement
train_pred_logreg = final_logreg.predict(X_train)
train_pred_rf = final_rf.predict(X_train)
train_pred_xgb = final_xgb.predict(X_train)

# √âtape 2 : Cr√©er un DataFrame avec ces pr√©dictions
train_meta_features = pd.DataFrame({
    'logreg_pred': train_pred_logreg,
    'rf_pred': train_pred_rf,
    'xgb_pred': train_pred_xgb
})

# √âtape 3 : Entra√Æner le mod√®le m√©ta (R√©gression Logistique) sur ces nouvelles caract√©ristiques
meta_model = LogisticRegression(max_iter=1000, random_state=42)
meta_model.fit(train_meta_features, y_train)

# √âtape 4 : G√©n√©rer les pr√©dictions des mod√®les de base sur le jeu de test
test_pred_logreg = final_logreg.predict(X_test)
test_pred_rf = final_rf.predict(X_test)
test_pred_xgb = final_xgb.predict(X_test)

# √âtape 5 : Cr√©er un DataFrame avec ces pr√©dictions
test_meta_features = pd.DataFrame({
    'logreg_pred': test_pred_logreg,
    'rf_pred': test_pred_rf,
    'xgb_pred': test_pred_xgb
})

# √âtape 6 : Faire des pr√©dictions avec le mod√®le empil√© (R√©gression Logistique)
y_test_pred = meta_model.predict(test_meta_features)

# √âtape 7 : Pr√©paration du fichier de soumission
submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': y_test_pred
})

# Sauvegarder le fichier de soumission
submission_file = 'submission.csv'
submission.to_csv(submission_file, index=False)

print(f"Fichier de soumission '{submission_file}' cr√©√© avec succ√®s !")

# √âtape 8 : T√©l√©charger le fichier de soumission
files.download(submission_file)

display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 11: Commandes GitHub
</h1>
"""))

!apt-get install git -y

!git config --global user.name "Mehdi-In-Coding"

!git config --global user.email "mbenayed09@gmail.com"

!git clone https://Mehdi-In-Coding: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@github.com/Mehdi-In-Coding/titanic-survival-predict.git

# Commented out IPython magic to ensure Python compatibility.
# %cd titanic-survival-predict

!mkdir -p src tests .github/workflows

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/data_preprocessing.py
# import pandas as pd
# import numpy as np
# 
# def preprocess_data(train_path, test_path):
#     train_df = pd.read_csv(train_path)
#     test_df = pd.read_csv(test_path)
# 
#     # Gestion des valeurs manquantes
#     train_df['Age'].fillna(train_df['Age'].median(), inplace=True)
#     test_df['Age'].fillna(test_df['Age'].median(), inplace=True)
# 
#     # Encodage des variables cat√©goriques
#     train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
#     test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})
# 
#     return train_df, test_df
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/model_training.py
# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import RandomForestClassifier
# import joblib
# 
# def train_models(train_df):
#     X = train_df.drop(columns=['Survived'])
#     y = train_df['Survived']
# 
#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
# 
#     # Entra√Ænement des mod√®les
#     logreg = LogisticRegression(max_iter=1000).fit(X_train, y_train)
#     rf = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)
# 
#     # Sauvegarde des mod√®les
#     joblib.dump(logreg, "models/logreg.pkl")
#     joblib.dump(rf, "models/random_forest.pkl")
# 
#     print("Mod√®les sauvegard√©s !")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/model_evaluation.py
# import joblib
# from sklearn.metrics import accuracy_score, classification_report
# 
# def evaluate_model(model_path, X_val, y_val):
#     model = joblib.load(model_path)
#     y_pred = model.predict(X_val)
# 
#     print(f"Accuracy: {accuracy_score(y_val, y_pred):.4f}")
#     print("Classification Report:")
#     print(classification_report(y_val, y_pred))
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/main.py
# from data_preprocessing import preprocess_data
# from model_training import train_models
# import pandas as pd
# 
# # Charger les donn√©es
# train_df, test_df = preprocess_data("data/train.csv", "data/test.csv")
# 
# # Entra√Æner les mod√®les
# train_models(train_df)

"""%%writefile tests/test_data_preprocessing.py
import pandas as pd
from src.data_preprocessing import preprocess_data

def test_preprocess_data():
    train_df, test_df = preprocess_data("data/train.csv", "data/test.csv")
    assert train_df.isnull().sum().sum() == 0, "Il reste des valeurs manquantes"
    assert "Sex" in train_df.columns, "Colonne Sex absente"
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/test_data_preprocessing.py
# import sys
# sys.path.append('/content/titanic-survival-predict/src')
# 
# import pandas as pd
# from src.data_preprocessing import preprocess_data
# 
# def test_preprocess_data():
#     train_df, test_df = preprocess_data("data/train.csv", "data/test.csv")
#     assert train_df.isnull().sum().sum() == 0, "Il reste des valeurs manquantes"
#     assert "Sex" in train_df.columns, "Colonne Sex absente"
# 
# 
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile tests/test_model_training.py
# import os
# from src.model_training import train_models
# import pandas as pd
# 
# def test_train_models():
#     train_df = pd.read_csv("data/train.csv")
#     train_models(train_df)
#     assert os.path.exists("models/logreg.pkl"), "Mod√®le logreg non sauvegard√©"
#     assert os.path.exists("models/random_forest.pkl"), "Mod√®le random forest non sauvegard√©"
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile .github/workflows/ci.yml
# name: CI Pipeline
# 
# on:
#   push:
#     branches:
#       - main
#       - develop
#   pull_request:
#     branches:
#       - main
#       - develop
# 
# jobs:
#   test:
#     runs-on: ubuntu-latest
#     steps:
#       - name: Checkout repository
#         uses: actions/checkout@v3
# 
#       - name: Set up Python
#         uses: actions/setup-python@v3
#         with:
#           python-version: "3.9"
# 
#       - name: Install dependencies
#         run: pip install -r requirements.txt
# 
#       - name: Run pytest (Tests)
#         run: pytest tests/
#

!git add .

!git commit -m "Structure initiale du projet avec modules, tests, et CI/CD"

print("la branche main du d√©p√¥t local est en retard par rapport √† celle du d√©p√¥t distant.\n Cela arrive souvent lorsqu'il y a d√©j√† des modifications sur GitHub qu'on n'a pas encore r√©cup√©r√©es localement.")

!git pull origin main --rebase

!git status

!git push -u origin main

!git checkout -b develop

!git push -u origin develop

!touch src/__init__.py

import sys
sys.path.append('/content/titanic-survival-predict/src')

from src.data_preprocessing import preprocess_data

!pytest tests/

#  partie1
#        partie_1_data_loading.py

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
from IPython.core.display import display, HTML

# D√©finir les styles visuels
plt.style.use('ggplot')
sns.set_context('notebook')

# üìå Affichage du titre de la section

# üöÄ Monter Google Drive
drive.mount('/content/drive')

# üîç Chemins des fichiers
TRAIN_PATH = "/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv"
TEST_PATH = "/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv"

# üìÇ V√©rifier si les fichiers existent
assert os.path.exists(TRAIN_PATH), f"‚ùå Le fichier {TRAIN_PATH} est introuvable."
assert os.path.exists(TEST_PATH), f"‚ùå Le fichier {TEST_PATH} est introuvable."

# üì• Charger les donn√©es
train_df = pd.read_csv(TRAIN_PATH)
test_df = pd.read_csv(TEST_PATH)

# ‚úÖ V√©rification que les DataFrames ne sont pas vides
assert not train_df.empty, "‚ùå Le DataFrame train_df est vide."
assert not test_df.empty, "‚ùå Le DataFrame test_df est vide."

# üîé Affichage des informations du jeu d'entra√Ænement
print("\nüìä Training Set Information:")
print(train_df.info())

# üîé Affichage des informations du jeu de test
print("\nüìä Test Set Information:")
print(test_df.info())

# üßê V√©rification des valeurs manquantes
print("\nüîé Valeurs manquantes dans le jeu d'entra√Ænement :")
print(train_df.isnull().sum())

print("\nüîé Valeurs manquantes dans le jeu de test :")
print(test_df.isnull().sum())

# ‚úÖ V√©rification
assert train_df.isnull().sum().sum() < 100, "‚ö†Ô∏è Trop de valeurs manquantes dans train_df."
assert test_df.isnull().sum().sum() < 100, "‚ö†Ô∏è Trop de valeurs manquantes dans test_df."

# üîç Aper√ßu des premi√®res lignes
print("\nüìå Les 5 premi√®res lignes du jeu d'entra√Ænement :")
print(train_df.head())

print("\nüìå Les 5 premi√®res lignes du jeu de test :")
print(test_df.head())

# üîé Exploration des donn√©es - Distribution de la variable cible
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Survived', palette='Set2')
plt.title('R√©partition de la variable Survived')
plt.show()

# üîé Distribution des classes de passagers (Pclass)
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Pclass', palette='Set3')
plt.title('R√©partition des classes de passagers (Pclass)')
plt.show()

# üîé Distribution de l'√¢ge par rapport √† la survie
plt.figure(figsize=(10, 6))
sns.histplot(train_df[train_df['Survived'] == 1]['Age'].dropna(), bins=20, color='green', label='Surv√©cu', kde=True)
sns.histplot(train_df[train_df['Survived'] == 0]['Age'].dropna(), bins=20, color='red', label='Non surv√©cu', kde=True)
plt.title('Distribution des √¢ges par rapport √† la survie')
plt.legend()
plt.show()

# üîé Matrice de corr√©lation pour v√©rifier les relations entre les variables num√©riques
plt.figure(figsize=(12, 8))
sns.heatmap(train_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matrice de corr√©lation')
plt.show()

print("\n‚úÖ Partie 1: Data Loading et Exploration des Donn√©es termin√©e avec succ√®s !")

#     partie 2 :
#     eda_analysis.py


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.core.display import display, HTML

# Chargement des donn√©es (√† modifier si n√©cessaire)
train_path = "/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv"
test_path = "/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv"

# Lecture des fichiers CSV
train_df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)

# Assertions pour v√©rifier que les datasets sont bien charg√©s
assert isinstance(train_df, pd.DataFrame), "Erreur: train_df n'est pas un DataFrame"
assert isinstance(test_df, pd.DataFrame), "Erreur: test_df n'est pas un DataFrame"

# V√©rification des colonnes essentielles
required_columns = ["Survived", "Pclass", "Age"]
for col in required_columns:
    assert col in train_df.columns, f"Erreur: La colonne {col} est absente du dataset d'entra√Ænement"

# V√©rification des valeurs manquantes
assert train_df.isnull().sum().sum() < len(train_df), "Erreur: Trop de valeurs manquantes dans train_df"
assert test_df.isnull().sum().sum() < len(test_df), "Erreur: Trop de valeurs manquantes dans test_df"

# Affichage du titre HTML
display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 2: Analyse Exploratoire des Donn√©es (EDA)
</h1>
"""))

# Configuration des styles pour les graphiques
plt.style.use('ggplot')
sns.set_context('notebook')

# √âtape 1 : Visualisation de la r√©partition de la variable 'Survived'
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Survived', palette='Set2')
plt.title('R√©partition de la variable Survived')
plt.show()

# √âtape 2 : Distribution des classes de passagers (Pclass)
plt.figure(figsize=(8, 6))
sns.countplot(data=train_df, x='Pclass', palette='Set3')
plt.title('R√©partition des classes de passagers (Pclass)')
plt.show()

# √âtape 3 : Distribution de l'√¢ge par rapport √† la survie
plt.figure(figsize=(10, 6))
sns.histplot(train_df[train_df['Survived'] == 1]['Age'].dropna(), bins=20, color='green', label='Surv√©cu', kde=True)
sns.histplot(train_df[train_df['Survived'] == 0]['Age'].dropna(), bins=20, color='red', label='Non surv√©cu', kde=True)
plt.title('Distribution des √¢ges par rapport √† la survie')
plt.legend()
plt.show()

# √âtape 4 : Matrice de corr√©lation des variables num√©riques
numeric_features = train_df.select_dtypes(include=[np.number])

plt.figure(figsize=(12, 8))
sns.heatmap(numeric_features.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matrice de corr√©lation')
plt.show()

# V√©rification finale des dimensions des datasets
assert train_df.shape[0] > 0, "Erreur: train_df est vide"
assert test_df.shape[0] > 0, "Erreur: test_df est vide"

print("\n‚úÖ Analyse exploratoire des donn√©es termin√©e avec succ√®s !")

# partie 3
#             data_preprocessing.py

import pandas as pd
import numpy as np

def preprocess_data(train_path, test_path):
    """
    Charge les donn√©es, applique le pr√©traitement et retourne les DataFrames transform√©s.
    """

    # Charger les fichiers CSV
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    ### V√©rification initiale ###
    assert train_df.shape[0] > 0, "Le fichier train est vide"
    assert test_df.shape[0] > 0, "Le fichier test est vide"

    print("‚úîÔ∏è Chargement des donn√©es r√©ussi")

    # √âtape 1 : Gestion des valeurs manquantes
    train_df['Age'] = train_df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))
    test_df['Age'] = test_df.groupby('Pclass')['Age'].transform(lambda x: x.fillna(x.median()))

    assert train_df['Age'].isnull().sum() == 0, "Il reste des valeurs manquantes dans Age (train)"
    assert test_df['Age'].isnull().sum() == 0, "Il reste des valeurs manquantes dans Age (test)"

    print("‚úîÔ∏è Remplissage des valeurs manquantes d'Age r√©ussi")

    train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)
    test_df['Fare'] = test_df.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))

    assert train_df['Embarked'].isnull().sum() == 0, "Il reste des valeurs manquantes dans Embarked (train)"
    assert test_df['Fare'].isnull().sum() == 0, "Il reste des valeurs manquantes dans Fare (test)"

    print("‚úîÔ∏è Remplissage des valeurs manquantes d'Embarked et Fare r√©ussi")

    # Encodage des variables cat√©goriques
    train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
    test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})

    train_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
    test_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

    assert 'Sex' in train_df.columns and train_df['Sex'].dtype == np.int64, "Probl√®me d'encodage de Sex"
    assert 'Embarked' in train_df.columns and train_df['Embarked'].dtype == np.int64, "Probl√®me d'encodage de Embarked"

    print("‚úîÔ∏è Encodage des variables cat√©goriques r√©ussi")

    # Cr√©ation de nouvelles variables
    train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1
    test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1

    train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)
    test_df['IsAlone'] = (test_df['FamilySize'] == 1).astype(int)

    assert 'FamilySize' in train_df.columns, "Colonne FamilySize absente"
    assert 'IsAlone' in train_df.columns, "Colonne IsAlone absente"

    print("‚úîÔ∏è Cr√©ation des nouvelles caract√©ristiques r√©ussie")

    # Supprimer les colonnes inutiles
    train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)
    test_df.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)

    print("‚úîÔ∏è Suppression des colonnes inutiles r√©ussie")

    return train_df, test_df


if __name__ == "__main__":
    # Ex√©cution du script en standalone avec assertions
    train_data_path = "/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv"
    test_data_path = "/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv"

    train_df, test_df = preprocess_data(train_data_path, test_data_path)

    print("‚úÖ Pr√©traitement des donn√©es termin√© avec succ√®s !")

#   partie 4

#         model_building.py


import pandas as pd
import numpy as np
import joblib
import os
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# Charger les donn√©es pr√©trait√©es
train_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv')

# V√©rification des donn√©es
assert 'Survived' in train_df.columns, "La colonne 'Survived' est absente"

# S√©paration des caract√©ristiques (X) et de la cible (y)
X = train_df.drop(columns=['Survived'])
y = train_df['Survived']

# V√©rification que les donn√©es sont correctes
assert not X.isnull().sum().any(), "NA sont pas un problemes pour les graphiques (on les hide)"
assert set(y.unique()).issubset({0, 1}), "y doit contenir uniquement des valeurs binaires (0 ou 1)"

# Division des donn√©es en ensembles d'entra√Ænement et de validation
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

assert X_train.shape[0] > 0 and X_val.shape[0] > 0, "Les ensembles d'entra√Ænement et de validation ne doivent pas √™tre vides"

# Fonction d'√©valuation des mod√®les
def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

    accuracy = accuracy_score(y_val, y_pred)
    print(f"\n--- {model_name} ---")
    print(f"Pr√©cision : {accuracy:.4f}")
    print("Matrice de confusion :")
    print(confusion_matrix(y_val, y_pred))
    print("\nRapport de classification :")
    print(classification_report(y_val, y_pred))

    return model

# Cr√©ation des mod√®les
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "RandomForest": RandomForestClassifier(n_estimators=100, random_state=42),
    "MLP Classifier": MLPClassifier(alpha=0.06, hidden_layer_sizes=(50, 50), learning_rate_init=0.03, max_iter=158),
    "XGBoost": xgb.XGBClassifier(use_label_encoder=False, enable_categorical=True, eval_metric='logloss', random_state=42)
}

# Entra√Ænement et √©valuation
trained_models = {}
for name, model in models.items():
    trained_models[name] = evaluate_model(model, X_train, y_train, X_val, y_val, name)

# Sauvegarde des mod√®les
models_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/models"
os.makedirs(models_path, exist_ok=True)

for name, model in trained_models.items():
    model_filename = os.path.join(models_path, f"{name.replace(' ', '_').lower()}.pkl")
    joblib.dump(model, model_filename)
    print(f"Mod√®le {name} sauvegard√© dans {model_filename}")

print("\n‚úÖ Tous les mod√®les ont √©t√© entra√Æn√©s et sauvegard√©s avec succ√®s !")

# partie 5

#      comparaison_modeles.py



import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score

# V√©rification des mod√®les et donn√©es
assert 'logreg' in globals(), "Le mod√®le de r√©gression logistique n'est pas d√©fini."
assert 'rf' in globals(), "Le mod√®le RandomForest n'est pas d√©fini."
assert 'xgb_model' in globals(), "Le mod√®le XGBoost n'est pas d√©fini."
assert 'X_train' in globals() and 'y_train' in globals(), "Les donn√©es d'entra√Ænement ne sont pas d√©finies."
assert len(X_train) > 0, "X_train est vide !"
assert len(y_train) > 0, "y_train est vide !"

# Dictionnaire des mod√®les
models = {
    'Logistic Regression': logreg,
    'RandomForest': rf,
    'XGBoost': xgb_model
}

# Configuration de la validation crois√©e
kf = KFold(n_splits=5, shuffle=True, random_state=42)

print("\n--- Scores de validation crois√©e (m√©thode manuelle) ---")

for name, model in models.items():
    scores = []
    for train_idx, val_idx in kf.split(X_train):
        X_t, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]
        y_t, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]

        model.fit(X_t, y_t)  # Entra√Ænement
        y_pred = model.predict(X_v)  # Pr√©diction

        scores.append(accuracy_score(y_v, y_pred))  # Calcul de l'accuracy

    mean_score = np.mean(scores)
    std_score = np.std(scores)
    print(f"{name}: {mean_score:.4f} (+/- {std_score:.4f})")

# partie 6

#             otpimisation.py



import joblib
from google.colab import files
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import numpy as np
import pandas as pd

# V√©rifier que les donn√©es existent
assert 'X_train' in globals(), "X_train n'est pas d√©fini"
assert 'y_train' in globals(), "y_train n'est pas d√©fini"

HO_TUNING = True  # Active l'optimisation manuelle

if HO_TUNING:
    print("\n--- Optimisation des hyperparam√®tres : R√©gression Logistique ---")
    logreg_params = {
        'C': [0.01, 0.1, 1, 10, 100],
        'solver': ['liblinear', 'lbfgs'],
        'max_iter': [200, 500, 1000]
    }

    logreg_grid = GridSearchCV(LogisticRegression(random_state=42), logreg_params, cv=5, scoring='accuracy')
    logreg_grid.fit(X_train, y_train)

    print(f"Meilleurs hyperparam√®tres pour la r√©gression logistique : {logreg_grid.best_params_}")
    best_logreg = logreg_grid.best_estimator_

    logreg_model_path = "/content/logistic_regression_model.pkl"
    joblib.dump(best_logreg, logreg_model_path)
    print(f"Mod√®le Regression Logistique sauvegard√© : {logreg_model_path}")
    files.download(logreg_model_path)

if HO_TUNING:
    print("\n--- Optimisation des hyperparam√®tres : RandomForest ---")
    rf_params = {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 10],
        'min_samples_leaf': [1, 5],
        'bootstrap': [True]
    }

    X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.2, random_state=42)
    rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=rf_params, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, verbose=2, random_state=42)
    rf_random.fit(X_train_sampled, y_train_sampled)

    print(f"Meilleurs hyperparam√®tres pour RandomForest : {rf_random.best_params_}")
    best_rf = rf_random.best_estimator_

    rf_model_path = "/content/random_forest_model.pkl"
    joblib.dump(best_rf, rf_model_path)
    print(f"Mod√®le RandomForest sauvegard√© : {rf_model_path}")
    files.download(rf_model_path)

if HO_TUNING:
    print("\n--- Optimisation des hyperparam√®tres : XGBoost ---")
    xgb_params = {
        'n_estimators': [100, 200, 500],
        'max_depth': [3, 6, 10],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 1.0],
        'colsample_bytree': [0.8, 1.0]
    }

    best_score = 0.0
    best_params = None
    for combo in (dict(zip(xgb_params.keys(), values)) for values in itertools.product(*xgb_params.values())):
        model = xgb.XGBClassifier(enable_categorical=True, eval_metric='logloss', random_state=42, **combo)
        model.fit(X_train, y_train)
        score = model.score(X_train, y_train)
        if score > best_score:
            best_score = score
            best_params = combo

    print(f"Meilleurs hyperparam√®tres pour XGBoost : {best_params}")
    best_xgb = xgb.XGBClassifier(enable_categorical=True, eval_metric='logloss', random_state=42, **best_params)
    best_xgb.fit(X_train, y_train)

    xgb_model_path = "/content/xgboost_model.pkl"
    joblib.dump(best_xgb, xgb_model_path)
    print(f"Mod√®le XGBoost sauvegard√© : {xgb_model_path}")
    files.download(xgb_model_path)

# partie 7


#         load_models.py

import joblib
import os

# D√©finir les chemins des mod√®les
logreg_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/logistic_regression_model.pkl"
rf_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/random_forest_model.pkl"
xgb_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/xgboost_model.pkl"

# V√©rifier l'existence des fichiers avant chargement
assert os.path.exists(logreg_model_path), f"Erreur: Le fichier {logreg_model_path} n'existe pas !"
assert os.path.exists(rf_model_path), f"Erreur: Le fichier {rf_model_path} n'existe pas !"
assert os.path.exists(xgb_model_path), f"Erreur: Le fichier {xgb_model_path} n'existe pas !"

# Charger les mod√®les
final_logreg = joblib.load(logreg_model_path)
final_rf = joblib.load(rf_model_path)
final_xgb = joblib.load(xgb_model_path)

# V√©rifier que les objets charg√©s sont bien des mod√®les
assert hasattr(final_logreg, "predict"), "Erreur: final_logreg n'est pas un mod√®le valide !"
assert hasattr(final_rf, "predict"), "Erreur: final_rf n'est pas un mod√®le valide !"
assert hasattr(final_xgb, "predict"), "Erreur: final_xgb n'est pas un mod√®le valide !"

print(f"‚úî Mod√®le de r√©gression logistique charg√© depuis {logreg_model_path}")
print(f"‚úî Mod√®le RandomForest charg√© depuis {rf_model_path}")
print(f"‚úî Mod√®le XGBoost charg√© depuis {xgb_model_path}")

# partie 8


# model_stacking.py



import pandas as pd
import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Chargement des mod√®les entra√Æn√©s
logreg_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/logistic_regression_model.pkl'
rf_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/random_forest_model.pkl'
xgb_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/xgboost_model.pkl'

final_logreg = joblib.load(logreg_model_path)
final_rf = joblib.load(rf_model_path)
final_xgb = joblib.load(xgb_model_path)

# Assertions pour v√©rifier que les mod√®les sont bien charg√©s
assert final_logreg is not None, "Le mod√®le Logistic Regression n'a pas √©t√© charg√©."
assert final_rf is not None, "Le mod√®le Random Forest n'a pas √©t√© charg√©."
assert final_xgb is not None, "Le mod√®le XGBoost n'a pas √©t√© charg√©."

# Chargement des donn√©es d'entra√Ænement et de validation
X_train = pd.read_csv('/content/drive/MyDrive/Titanic-Survival-Predict-main/X_train.csv')
X_val = pd.read_csv('/content/drive/MyDrive/Titanic-Survival-Predict-main/X_val.csv')
y_train = pd.read_csv('/content/drive/MyDrive/Titanic-Survival-Predict-main/y_train.csv').values.ravel()
y_val = pd.read_csv('/content/drive/MyDrive/Titanic-Survival-Predict-main/y_val.csv').values.ravel()

# Assertions pour v√©rifier que les donn√©es sont bien charg√©es
assert X_train.shape[0] > 0, "X_train est vide."
assert X_val.shape[0] > 0, "X_val est vide."
assert y_train.shape[0] > 0, "y_train est vide."
assert y_val.shape[0] > 0, "y_val est vide."

# √âtape 1 : G√©n√©rer des pr√©dictions des mod√®les de base sur l'ensemble d'entra√Ænement
print("\n--- G√©n√©ration des pr√©dictions des mod√®les de base sur l'ensemble d'entra√Ænement ---")
train_pred_logreg = final_logreg.predict(X_train)
train_pred_rf = final_rf.predict(X_train)
train_pred_xgb = final_xgb.predict(X_train)

# Cr√©er un DataFrame avec ces pr√©dictions
train_meta_features = pd.DataFrame({
    'logreg_pred': train_pred_logreg,
    'rf_pred': train_pred_rf,
    'xgb_pred': train_pred_xgb
})

print("Pr√©dictions des mod√®les de base g√©n√©r√©es avec succ√®s.")

# √âtape 2 : Entra√Æner le Mod√®le Meta sur ces Pr√©dictions
print("\n--- Entra√Ænement du mod√®le Meta (R√©gression Logistique) ---")
meta_model = LogisticRegression(max_iter=1000, random_state=42)
meta_model.fit(train_meta_features, y_train)
print("Mod√®le Meta entra√Æn√© avec succ√®s.")

# √âtape 3 : G√©n√©rer des pr√©dictions des mod√®les de base sur l'ensemble de validation
print("\n--- G√©n√©ration des pr√©dictions des mod√®les de base sur l'ensemble de validation ---")
val_pred_logreg = final_logreg.predict(X_val)
val_pred_rf = final_rf.predict(X_val)
val_pred_xgb = final_xgb.predict(X_val)

# Cr√©er un DataFrame avec ces pr√©dictions
val_meta_features = pd.DataFrame({
    'logreg_pred': val_pred_logreg,
    'rf_pred': val_pred_rf,
    'xgb_pred': val_pred_xgb
})

print("Pr√©dictions des mod√®les de base sur l'ensemble de validation g√©n√©r√©es avec succ√®s.")

# √âtape 4 : Utiliser le Mod√®le Meta pour Pr√©dire sur l'Ensemble de Validation
print("\n--- Pr√©diction avec le mod√®le Meta ---")
y_pred_stack = meta_model.predict(val_meta_features)

# √âtape 5 : √âvaluer les Performances
print("\n--- √âvaluation des Performances du Mod√®le Empil√© ---")
stack_accuracy = accuracy_score(y_val, y_pred_stack)
print(f"Accuracy du mod√®le empil√© : {stack_accuracy:.4f}")

print("Matrice de confusion du mod√®le empil√© :")
print(confusion_matrix(y_val, y_pred_stack))

print("\nRapport de classification du mod√®le empil√© :")
print(classification_report(y_val, y_pred_stack))

# Optionnel : Sauvegarder le Mod√®le Meta
stack_meta_model_path = "/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/stacking_meta_model.pkl"
joblib.dump(meta_model, stack_meta_model_path)
print(f"\nLe mod√®le empil√© (meta) est bien sauvegard√© dans {stack_meta_model_path}")

# partie 9

#       xai.py



import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
from sklearn.inspection import permutation_importance

# Assurer que les mod√®les et les donn√©es existent
assert 'logreg' in globals(), "Le mod√®le de r√©gression logistique (logreg) n'est pas d√©fini."
assert 'rf' in globals(), "Le mod√®le RandomForest (rf) n'est pas d√©fini."
assert 'mlp' in globals(), "Le mod√®le MLP (mlp) n'est pas d√©fini."
assert 'X_train' in globals(), "X_train n'est pas d√©fini."
assert 'X_val' in globals(), "X_val n'est pas d√©fini."
assert 'y_val' in globals(), "y_val n'est pas d√©fini."

print("Toutes les assertions sont valid√©es. Ex√©cution du code XAI...")

# ---- Explication avec SHAP pour RandomForest ----
explainer = shap.Explainer(rf)
shap_values = explainer(X_train)

# Visualisation SHAP pour la premi√®re observation
plt.title("Graphique en cascade SHAP pour la premi√®re observation")
shap.plots.waterfall(shap_values[0, :, 1])
plt.show()

# ---- Analyse des coefficients pour la r√©gression logistique ----
coefficients = logreg.coef_[0]
feature_names = X_train.columns
coef_feature_pairs = sorted(zip(coefficients, feature_names), key=lambda x: abs(x[0]), reverse=True)

# S√©lection des 10 principales caract√©ristiques
sorted_coefficients, sorted_feature_names = zip(*coef_feature_pairs[:10])
plt.figure(figsize=(10, 6))
plt.barh(sorted_feature_names, sorted_coefficients, color='skyblue')
plt.xlabel('Valeur des coefficients')
plt.ylabel('Nom des caract√©ristiques')
plt.title('Top 10 des coefficients de la r√©gression logistique')
plt.gca().invert_yaxis()
plt.show()

# ---- Analyse des importances des caract√©ristiques pour RandomForest ----
importances = rf.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)

# S√©lection des 10 principales caract√©ristiques
top_features = feature_importance_df.head(10)
plt.figure(figsize=(12, 6))
plt.barh(top_features['Feature'], top_features['Importance'], color='lightgreen')
plt.xlabel('Importance des caract√©ristiques')
plt.ylabel('Nom des caract√©ristiques')
plt.title('Top 10 des caract√©ristiques les plus importantes (RandomForest)')
plt.gca().invert_yaxis()
plt.show()

# ---- Importances par permutation pour MLP ----
perm_importance = permutation_importance(mlp, X_val, y_val, n_repeats=10, random_state=42)
feature_importances = perm_importance.importances_mean
sorted_idx = feature_importances.argsort()[::-1]

# S√©lection des 10 principales caract√©ristiques
top_features = [X_train.columns[i] for i in sorted_idx[:10]]
top_importances = feature_importances[sorted_idx[:10]]
plt.figure(figsize=(10, 6))
plt.barh(top_features, top_importances, color='cornflowerblue')
plt.xlabel("Importance des caract√©ristiques")
plt.ylabel("Nom des caract√©ristiques")
plt.title("Top 10 importances des caract√©ristiques par permutation")
plt.gca().invert_yaxis()
plt.show()

print("Analyse XAI termin√©e avec succ√®s !")

# main.py


import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import shap
import xgboost as xgb

from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance

# D√©finition des chemins
MODELS_PATH = "/content/drive/MyDrive/Titanic-Survival-Predict-main/models"

# Chargement des donn√©es
train_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/train_cleaned.csv')
test_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv')

# V√©rification des donn√©es
assert train_df.shape[0] > 0, "Le dataset d'entra√Ænement est vide"
assert test_df.shape[0] > 0, "Le dataset de test est vide"

# Pr√©paration des donn√©es
X = train_df.drop(columns=['Survived'])
y = train_df['Survived']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Entra√Ænement des mod√®les
print("\n--- Entra√Ænement des mod√®les de base ---")
logreg = LogisticRegression(max_iter=1000, random_state=42).fit(X_train, y_train)
rf = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)
mlp = MLPClassifier(alpha=0.06, hidden_layer_sizes=(50, 50), learning_rate_init=0.03, max_iter=158).fit(X_train, y_train)
xgb_model = xgb.XGBClassifier(use_label_encoder=False, enable_categorical=True, eval_metric='logloss', random_state=42).fit(X_train, y_train)

# V√©rification des mod√®les
assert logreg, "Erreur lors de l'entra√Ænement de la R√©gression Logistique"
assert rf, "Erreur lors de l'entra√Ænement du RandomForest"
assert mlp, "Erreur lors de l'entra√Ænement du MLP"
assert xgb_model, "Erreur lors de l'entra√Ænement de XGBoost"

# √âvaluation des mod√®les
print("\n--- √âvaluation des mod√®les de base ---")
for model, name in zip([logreg, rf, mlp, xgb_model], ["Logistic Regression", "RandomForest", "MLP", "XGBoost"]):
    y_pred = model.predict(X_val)
    acc = accuracy_score(y_val, y_pred)
    f1 = classification_report(y_val, y_pred, output_dict=True)["macro avg"]["f1-score"]
    print(f"{name} - Accuracy: {acc:.4f}, F1-Score: {f1:.4f}")

# Sauvegarde des mod√®les
print("\n--- Sauvegarde des mod√®les ---")
os.makedirs(MODELS_PATH, exist_ok=True)
joblib.dump(logreg, f"{MODELS_PATH}/logreg.pkl")
joblib.dump(rf, f"{MODELS_PATH}/random_forest.pkl")
joblib.dump(mlp, f"{MODELS_PATH}/mlp.pkl")
joblib.dump(xgb_model, f"{MODELS_PATH}/xgboost.pkl")

print(f"Les mod√®les ont √©t√© sauvegard√©s dans {MODELS_PATH}")

# Chargement des mod√®les sauvegard√©s pour validation
print("\n--- Chargement des mod√®les sauvegard√©s ---")
logreg_loaded = joblib.load(f"{MODELS_PATH}/logreg.pkl")
rf_loaded = joblib.load(f"{MODELS_PATH}/random_forest.pkl")
mlp_loaded = joblib.load(f"{MODELS_PATH}/mlp.pkl")
xgb_loaded = joblib.load(f"{MODELS_PATH}/xgboost.pkl")

assert logreg_loaded, "Erreur lors du chargement de la R√©gression Logistique"
assert rf_loaded, "Erreur lors du chargement du RandomForest"
assert mlp_loaded, "Erreur lors du chargement du MLP"
assert xgb_loaded, "Erreur lors du chargement du XGBoost"

print("Les mod√®les ont √©t√© correctement charg√©s.")

# Passage √† la Partie 9 (IA Explicable)
print("\n--- Ex√©cution de la Partie 9: IA Explicable (XAI) ---")
os.system("python partie9_xai.py")

# partie 10

#       submission.py


import pandas as pd
import joblib
from sklearn.linear_model import LogisticRegression
from google.colab import files
from IPython.core.display import display, HTML

# Affichage d'un titre stylis√©
display(HTML("""
<h1 style="color:#2c3e50; font-size: 32px; font-weight: bold; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);">
Partie 10: Cr√©ation du fichier de soumission
</h1>
"""))

# ================================
# ‚ö° CHARGEMENT DES DONN√âES
# ================================

# Charger les fichiers de test
test_df = pd.read_csv('/content/drive/My Drive/Titanic-Survival-Predict-main/test_cleaned.csv')

# V√©rifier que la colonne PassengerId existe
assert 'PassengerId' in test_df.columns, "üö® ERREUR : La colonne 'PassengerId' est absente du dataset test !"

# Extraire les caract√©ristiques
X_test = test_df.drop(columns=['PassengerId'])

# V√©rifier que X_test n'est pas vide
assert not X_test.empty, "üö® ERREUR : Le dataset X_test est vide apr√®s suppression de 'PassengerId' !"

# ================================
# ‚ö° CHARGEMENT DES MOD√àLES
# ================================

# D√©finir les chemins des mod√®les
logreg_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/logistic_regression_model.pkl'
rf_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/random_forest_model.pkl'
xgb_model_path = '/content/drive/MyDrive/Titanic-Survival-Predict-main/Models/xgboost_model.pkl'

# Charger les mod√®les
final_logreg = joblib.load(logreg_model_path)
final_rf = joblib.load(rf_model_path)
final_xgb = joblib.load(xgb_model_path)

# V√©rifier que les mod√®les sont bien charg√©s
assert isinstance(final_logreg, LogisticRegression), "üö® ERREUR : Le mod√®le LogisticRegression n'est pas charg√© correctement !"
assert hasattr(final_rf, "predict"), "üö® ERREUR : Le mod√®le RandomForest n'est pas charg√© correctement !"
assert hasattr(final_xgb, "predict"), "üö® ERREUR : Le mod√®le XGBoost n'est pas charg√© correctement !"

# ================================
# ‚ö° PR√âDICTION DES MOD√àLES DE BASE
# ================================

print("\n--- G√©n√©ration des pr√©dictions des mod√®les de base sur le jeu de test ---")

# Faire les pr√©dictions avec chaque mod√®le
test_pred_logreg = final_logreg.predict(X_test)
test_pred_rf = final_rf.predict(X_test)
test_pred_xgb = final_xgb.predict(X_test)

# V√©rifier que les pr√©dictions ont la bonne taille
assert len(test_pred_logreg) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions logreg !"
assert len(test_pred_rf) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions rf !"
assert len(test_pred_xgb) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions xgb !"

# Cr√©er un DataFrame avec ces pr√©dictions
test_meta_features = pd.DataFrame({
    'logreg_pred': test_pred_logreg,
    'rf_pred': test_pred_rf,
    'xgb_pred': test_pred_xgb
})

print("‚úÖ Pr√©dictions des mod√®les de base sur le jeu de test g√©n√©r√©es avec succ√®s.")

# ================================
# ‚ö° ENTRA√éNEMENT DU MOD√àLE M√âTA
# ================================

print("\n--- Entra√Ænement du mod√®le Meta (R√©gression Logistique) ---")

# G√©n√©rer les pr√©dictions sur l'entra√Ænement pour cr√©er un mod√®le m√©ta
train_pred_logreg = final_logreg.predict(X_test)
train_pred_rf = final_rf.predict(X_test)
train_pred_xgb = final_xgb.predict(X_test)

# V√©rifier que les pr√©dictions sont valides
assert len(train_pred_logreg) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions logreg sur le train !"
assert len(train_pred_rf) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions rf sur le train !"
assert len(train_pred_xgb) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions xgb sur le train !"

# Cr√©er le dataset pour le mod√®le m√©ta
train_meta_features = pd.DataFrame({
    'logreg_pred': train_pred_logreg,
    'rf_pred': train_pred_rf,
    'xgb_pred': train_pred_xgb
})

# Entra√Æner le mod√®le m√©ta (R√©gression Logistique)
meta_model = LogisticRegression(max_iter=1000, random_state=42)
meta_model.fit(train_meta_features, test_pred_logreg)

print("‚úÖ Mod√®le Meta entra√Æn√© avec succ√®s.")

# ================================
# ‚ö° PR√âDICTION FINALE
# ================================

print("\n--- Pr√©diction avec le mod√®le Meta ---")

# Faire les pr√©dictions finales
y_test_pred = meta_model.predict(test_meta_features)

# V√©rifier la taille des pr√©dictions finales
assert len(y_test_pred) == len(X_test), "üö® ERREUR : Probl√®me de taille des pr√©dictions finales du mod√®le m√©ta !"

# ================================
# ‚ö° CR√âATION DU FICHIER DE SOUMISSION
# ================================

print("\n--- Cr√©ation du fichier de soumission ---")

# Cr√©er le fichier de soumission
submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': y_test_pred
})

# Sauvegarde en CSV
submission_file = 'submission.csv'
submission.to_csv(submission_file, index=False)

# V√©rifier que le fichier est bien sauvegard√©
assert os.path.exists(submission_file), f"üö® ERREUR : Le fichier {submission_file} n'a pas √©t√© cr√©√© !"

print(f"‚úÖ Fichier de soumission '{submission_file}' cr√©√© avec succ√®s !")

# ================================
# ‚ö° T√âL√âCHARGEMENT DU FICHIER
# ================================
files.download(submission_file)
print("‚úÖ T√©l√©chargement du fichier termin√©.")

